# Ghid Complet - Setup Lambda Labs pentru Training

## ğŸ¯ Overview

Acest ghid te va ajuta sÄƒ configurezi complet proiectul pentru training pe Lambda Labs cu GPU A10 (24GB).

**Cost estimat:** ~$13.50-18 EUR pentru toate cele 3 modele (18-24 ore training)

---

## ğŸ“‹ Pasul 1: Creare Cont È™i Launch Instance

### 1.1 Creare cont
1. Mergi la [lambdalabs.com](https://lambdalabs.com)
2. CreeazÄƒ cont (Sign Up)
3. VerificÄƒ email-ul

### 1.2 Launch Instance
1. Click pe **"Instances"** â†’ **"Launch instance"**
2. SelecteazÄƒ:
   - **Instance type:** `1x A10 (24 GB PCIe)` - $0.75/hr
   - **Region:** `Virginia, USA (us-east-1)` (cel mai aproape de RomÃ¢nia)
   - **Base image:** `Lambda Stack 22.04` (sau `PyTorch 2.0`)
   - **Filesystem:** `Don't attach a filesystem` (pentru primul training)
   - **Security:** AdaugÄƒ SSH key (sau genereazÄƒ una nouÄƒ)
3. Click **"Launch instance"**

### 1.3 Conectare SSH
DupÄƒ ce instanÈ›a porneÈ™te, vei primi un SSH command de forma:
```bash
ssh ubuntu@<ip-address>
```

CopiazÄƒ È™i ruleazÄƒ comanda Ã®n terminal-ul tÄƒu.

---

## ğŸ“¦ Pasul 2: Setup Initial pe Lambda Labs

### 2.1 Conectare È™i verificare
```bash
# ConecteazÄƒ-te la instanÈ›Äƒ
ssh ubuntu@<ip-address>

# VerificÄƒ GPU
nvidia-smi

# VerificÄƒ Python
python3 --version
```

### 2.2 CloneazÄƒ repository-ul
```bash
# CloneazÄƒ repository-ul
git clone https://github.com/andreeatomescu16/DR-Classification.git
cd DR-Classification

# VerificÄƒ structura
ls -la
```

### 2.3 RuleazÄƒ setup script
```bash
# Face script-ul executabil
chmod +x setup_cloud.sh

# RuleazÄƒ setup (va instala toate dependenÈ›ele)
bash setup_cloud.sh
```

Setup-ul va:
- Instala Python dependencies
- Crea virtual environment
- Instala PyTorch cu CUDA
- Instala toate pachetele necesare
- Verifica GPU availability

---

## ğŸ“¥ Pasul 3: Download Dataset-uri

### OpÈ›iunea A: Download direct de pe Kaggle (RECOMANDAT)

```bash
# ActiveazÄƒ virtual environment
source venv/bin/activate

# InstaleazÄƒ Kaggle API (dacÄƒ nu e deja instalat)
pip install kaggle

# ConfigureazÄƒ Kaggle API
mkdir -p ~/.kaggle
nano ~/.kaggle/kaggle.json
# AdaugÄƒ:
# {
#   "username": "andreeatomescu",
#   "key": "KGAT_fa40c59d94f34c394164777195788046"
# }
chmod 600 ~/.kaggle/kaggle.json

# Download dataset combinat
mkdir -p data/combined_dataset
cd data/combined_dataset

# Download (va dura 15-45 minute)
kaggle datasets download -d ascanipek/eyepacs-aptos-messidor-diabetic-retinopathy

# DezarhiveazÄƒ
unzip eyepacs-aptos-messidor-diabetic-retinopathy.zip
# È˜terge zip-ul pentru a economisi spaÈ›iu
rm *.zip

cd ../..
```

### OpÈ›iunea B: Transfer de pe laptop (dacÄƒ ai deja dataset-ul)

```bash
# Pe laptop-ul tÄƒu, ruleazÄƒ:
scp -r /path/to/dataset ubuntu@<ip-address>:~/DR-Classification/data/
```

---

## ğŸ”§ Pasul 4: Procesare Dataset-uri

DupÄƒ download, proceseazÄƒ dataset-urile:

```bash
# ActiveazÄƒ environment
source venv/bin/activate

# ProceseazÄƒ dataset-ul combinat
python scripts/prepare_combined_dataset.py \
    --dataset_dir data/combined_dataset \
    --output_dir data

# CreeazÄƒ K-fold splits
python scripts/kfold_split.py \
    --masters data/eyepacs_master.csv data/aptos_master.csv \
    --out_dir data/folds \
    --n_splits 5 \
    --seed 42
```

---

## ğŸš€ Pasul 5: Training Modele

### 5.1 Setup Screen pentru sesiune persistentÄƒ

```bash
# InstaleazÄƒ screen (dacÄƒ nu e instalat)
sudo apt-get install -y screen

# CreeazÄƒ sesiune screen
screen -S training

# DacÄƒ te deconectezi, reattach cu:
# screen -r training
```

### 5.2 RuleazÄƒ Training

```bash
# ActiveazÄƒ environment
source venv/bin/activate

# RuleazÄƒ benchmark (toate cele 3 modele)
python scripts/benchmark.py \
    --fold_csv data/folds/fold0.csv \
    --epochs 30 \
    --batch_size 32 \
    --num_workers 8 \
    --log_dir benchmark_results/logs

# Sau antreneazÄƒ un singur model:
python -m drlib.train \
    --fold_csv data/folds/fold0.csv \
    --model efficientnet_b2.ra_in1k \
    --img_size 384 \
    --batch_size 32 \
    --epochs 30 \
    --lr 1e-4 \
    --loss weighted_ce \
    --use_class_weights \
    --lr_scheduler cosine \
    --patience 10 \
    --monitor val_qwk \
    --seed 42 \
    --num_workers 8
```

### 5.3 Monitorizare Training

Ãn alt terminal (pe laptop):
```bash
# ConecteazÄƒ-te la instanÈ›Äƒ
ssh ubuntu@<ip-address>

# VerificÄƒ progresul
tail -f benchmark_results/logs/EfficientNet-B2_training.log

# Sau foloseÈ™te script-ul de monitoring
python scripts/monitor_training.py
```

---

## ğŸ’¾ Pasul 6: Backup Rezultate

### 6.1 Download checkpoint-uri È™i rezultate

```bash
# Pe laptop-ul tÄƒu, ruleazÄƒ:
scp -r ubuntu@<ip-address>:~/DR-Classification/lightning_logs ./backup/
scp -r ubuntu@<ip-address>:~/DR-Classification/benchmark_results ./backup/
```

### 6.2 Sau foloseÈ™te script-ul de backup

```bash
# Pe instanÈ›Äƒ, ruleazÄƒ:
bash scripts/backup_results.sh

# Va crea un tar.gz cu toate rezultatele
# Apoi download:
scp ubuntu@<ip-address>:~/DR-Classification/results_backup.tar.gz ./
```

---

## âš™ï¸ Configurare OptimizatÄƒ pentru A10 GPU

### Batch Size Recommendations:
- **EfficientNet-B2 (384Ã—384):** `batch_size=32` (optim pentru 24GB VRAM)
- **EfficientNet-B4 (384Ã—384):** `batch_size=16-24` (depinde de memorie)
- **ViT-B/16 (224Ã—224):** `batch_size=32-48` (optim pentru 24GB VRAM)

### num_workers:
- SeteazÄƒ `num_workers=8` pentru A10 (CPU-uri multiple disponibile)
- Va accelera semnificativ data loading

### Mixed Precision (opÈ›ional):
Pentru training mai rapid, poÈ›i activa mixed precision Ã®n `drlib/train.py`:
```python
trainer = L.Trainer(
    precision="16-mixed",  # Ãn loc de "32-true"
    ...
)
```

---

## ğŸ” Troubleshooting

### Problema: "Out of Memory (OOM)"
**SoluÈ›ie:**
```bash
# Reduce batch_size
python scripts/benchmark.py --batch_size 16 --num_workers 8
```

### Problema: "Connection lost"
**SoluÈ›ie:**
```bash
# FoloseÈ™te screen pentru sesiuni persistente
screen -S training
# RuleazÄƒ training-ul Ã®n screen
# Detach: Ctrl+A apoi D
# Reattach: screen -r training
```

### Problema: "Training prea lent"
**SoluÈ›ie:**
```bash
# VerificÄƒ cÄƒ GPU este folosit
nvidia-smi

# VerificÄƒ cÄƒ num_workers > 0
python scripts/benchmark.py --num_workers 8
```

### Problema: "Dataset download failed"
**SoluÈ›ie:**
```bash
# VerificÄƒ Kaggle credentials
cat ~/.kaggle/kaggle.json

# VerificÄƒ cÄƒ ai acceptat termenii pentru dataset
# Mergi la: https://www.kaggle.com/datasets/ascanipek/eyepacs-aptos-messidor-diabetic-retinopathy
# Click "Download" pentru a accepta termenii
```

---

## ğŸ“Š Monitorizare Costuri

### VerificÄƒ costurile Ã®n timp real:
1. Mergi la [Lambda Labs Dashboard](https://lambdalabs.com/instances)
2. Vezi costul acumulat pentru instanÈ›a ta
3. SeteazÄƒ alertÄƒ pentru limitÄƒ de cost (opÈ›ional)

### Estimare costuri:
- **EfficientNet-B2:** ~4-6 ore Ã— $0.75 = $3-4.50
- **EfficientNet-B4:** ~6-8 ore Ã— $0.75 = $4.50-6
- **ViT-B/16:** ~8-10 ore Ã— $0.75 = $6-7.50
- **Total:** ~$13.50-18 EUR

---

## âœ… Checklist Final

Ãnainte de a Ã®ncepe training-ul, verificÄƒ:

- [ ] InstanÈ›a Lambda Labs este pornitÄƒ È™i funcÈ›ionalÄƒ
- [ ] GPU este detectat (`nvidia-smi` funcÈ›ioneazÄƒ)
- [ ] Repository-ul este clonat È™i setup-ul este complet
- [ ] Dataset-urile sunt descÄƒrcate È™i procesate
- [ ] K-fold splits sunt create (`data/folds/fold0.csv` existÄƒ)
- [ ] Screen session este creat pentru persistenÈ›Äƒ
- [ ] Backup plan este Ã®n loc (È™tii cum sÄƒ descarci rezultatele)

---

## ğŸ“ Next Steps

DupÄƒ ce training-ul este complet:

1. **Download rezultatele** (checkpoint-uri, metrics, visualizÄƒri)
2. **OpreÈ™te instanÈ›a** pentru a economisi bani
3. **AnalizeazÄƒ rezultatele** local pe laptop
4. **Scrie secÈ›iunea de rezultate** pentru licenÈ›Äƒ

---

## ğŸ“š Resurse Suplimentare

- [Lambda Labs Documentation](https://lambdalabs.com/docs)
- [PyTorch Lightning Docs](https://lightning.ai/docs/pytorch/stable/)
- [Kaggle API Docs](https://www.kaggle.com/docs/api)

---

**Succes cu training-ul! ğŸš€**
